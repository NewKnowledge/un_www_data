{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pprint\n",
    "from nltk import Tree\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data/survey_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Idenify Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = \"\"\"\n",
    "    NP: {<JJ>*<NN*>+}\n",
    "    {<JJ>*<NN*><CC>*<NN*>+}\n",
    "    \"\"\"\n",
    "\n",
    "NPChunker = nltk.RegexpParser(patterns)\n",
    "\n",
    "def prepare_text(input):\n",
    "    sentences = nltk.sent_tokenize(input)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    sentences = [NPChunker.parse(sent) for sent in sentences]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def parsed_text_to_NP(sentences):\n",
    "    nps = []\n",
    "    for sent in sentences:\n",
    "        tree = NPChunker.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                t = subtree\n",
    "                t = ' '.join(word for word, tag in t.leaves())\n",
    "                nps.append(t)\n",
    "    return nps\n",
    "\n",
    "def find_nps(text):\n",
    "    prepared = prepare_text(text)\n",
    "    parsed = parsed_text_to_NP(prepared)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Output A List Of Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_of_noun_phrases(series):\n",
    "\n",
    "    nouns = []\n",
    "\n",
    "    for row in series.dropna():\n",
    "        nouns.append(find_nps(row))\n",
    "        \n",
    "    list_of_nouns = [i.lower() for row in nouns for i in row]\n",
    "    \n",
    "    list_of_list_of_nouns = [[x[0]] * x[1] for x in Counter(list_of_nouns).most_common(30)]\n",
    "    \n",
    "    flattened_list_of_nouns = [i.lower() for row in list_of_list_of_nouns for i in row]\n",
    "    \n",
    "    titlecased_list_of_nouns = [x.title() for x in flattened_list_of_nouns]\n",
    "    \n",
    "    return titlecased_list_of_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create List Of Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_helped_women = pd.DataFrame()\n",
    "df_helped_women['What Helps Women?'] = list_of_noun_phrases(df['What Helps Women?'])\n",
    "\n",
    "df_barriers = pd.DataFrame()\n",
    "df_barriers['What Are Barriers To Women?'] = list_of_noun_phrases(df['What Are Barriers To Women?'])\n",
    "\n",
    "df_helped_you = pd.DataFrame()\n",
    "df_helped_you['What Helped You The Most?'] = list_of_noun_phrases(df['What Helped You The Most?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_helped_women.to_csv('clean_data/helped_women_data.csv')\n",
    "df_barriers.to_csv('clean_data/barriers_data.csv')\n",
    "df_helped_you.to_csv('clean_data/helped_you_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
